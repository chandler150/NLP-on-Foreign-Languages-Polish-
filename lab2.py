# -*- coding: utf-8 -*-
"""Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hWpu3Wah-Z2gf5pcc2x8DYOpy4wJmZgP
"""

#Shortens Code Output
from google.colab.output import eval_js
eval_js('google.colab.output.setIframeHeight("500")')

!mkdir data
!cd data
!wget http://users.csc.calpoly.edu/~foaad/Solidarno%C5%9Bci.tgz
!tar -zxvf Solidarności.tgz

#Shortens Code Output
from google.colab.output import eval_js
eval_js('google.colab.output.setIframeHeight("500")')

!pip install spacy
!pip install bs4

import os
from bs4 import BeautifulSoup
import spacy
!pip3 install -U spacy
#!python3 -m spacy download pl_core_news_sm
#!pip install spacy.pipeline
import pl_core_news_sm

#nlp = spacy.load('pl_core_news_sm')
#from spacy.lang.pl.examples import sentences 

import re
import pandas as pd
import bs4
import requests
import spacy
from spacy import displacy

from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')
from nltk.corpus import stopwords
!pip install stop-words
from stop_words import get_stop_words

stop_words = get_stop_words('polish')
print(stop_words)
from nltk.tokenize import RegexpTokenizer



from spacy.matcher import Matcher 
from spacy.tokens import Span 

import networkx as nx

import matplotlib.pyplot as plt
from tqdm import tqdm

#Shortens Code Output
from google.colab.output import eval_js
eval_js('google.colab.output.setIframeHeight("500")')

tokenizer = RegexpTokenizer(r'\w+')

phone = [] # A list to store all the phone
path = '/content/Solidarności/biogramy' # This is your folder name which stores all your html 
#be careful that you might need to put a full path such as C:\Users\Niche\Desktop\htmlfolder 
def present_in_href(check_string):
        return lambda tag: tag.get("href") and check_string in tag.get("href")
count = 0

for filename in os.listdir(path): #Read files from your path
     #Here we are trying to find the full pathname
  #print("\n", "\n")
  #print(filename)
  #print("\n", "\n")
  subpath = os.path.join(path, filename)
  if filename.endswith('.html'):
      soup = BeautifulSoup(open(subpath), 'lxml')
      
      # Gets Name
      name = soup.find("meta",  property="og:title")
      name = (name["content"])

      # Gets Brief Description

      description = soup.find("meta",  property="og:description")
      #author = soup.find_all("meta",  name="author")
      #print(description.attrs)           #attributes, use like dictionary
      #print(description['content'])       #Specific attribute I'll be using
      description = description['content']
      
      #print(description)
      # Parse Description
      parser = tokenizer.tokenize(description)
      #print(parser)
      for i in range(len(parser)):
        if parser[i] == 'ur':
          birthday = parser[i+1:i+4]
        elif parser[i] == 'Ukończył':
              school = parser[i+1:]
        elif parser[i] == 'Absolwent':
              school = parser[i+1:]
        elif parser[i] == 'Absolwentka':
              school = parser[i+1:]
      # Gets Region each Person was Related to

      region = soup.find_all(present_in_href("/es/tagi"))
      #print(region)
      regiontext = []
      for i in region[1:]:
        regiontext.append(i.get('href').split(',')[1][:-5])
      #print(regiontext) #List of generally two regions associated with each person
      

      # the last thing to get would be the next body of text, first I will do some analysis with the brief description

      #Now before iterating, put all these things into a nested dictionary
      if count == 0:
        people = {count: {'name': name, 'description': description, 'region': regiontext, 'birthday' : birthday, 'school': school}}
      else:
        people[count] = {'name': name, 'description': description, 'region': regiontext, 'birthday': birthday, 'school': school}
      
      count = count+ 1

      #print(soup)
      '''contactname = page_soup.findAll("td", {"itemprop": "name"})
      contactstreetaddress = page_soup.findAll("td", {"itemprop": "streetAddress"})
      contactpostalcode = page_soup.findAll("td", {"itemprop": "postalCode"})
      contactaddressregion = page_soup.findAll("td", {"itemprop": "addressRegion"})
      contactaddresscountry = page_soup.findAll("td", {"itemprop": "addressCountry"})
      contactfax = page_soup.findAll("td", {"itemprop": "faxNumber"})
      contactemail = page_soup.findAll("td", {"itemprop": "email"})
      contactphone = page_soup.findAll("td", {"itemprop": "telephone"})
      contacturl = page_soup.findAll("a", {"itemprop": "url"})
      #Outputs as text without tags
      Company = contactname[0].text
      Address = contactstreetaddress[0].text
      Zip = contactpostalcode[0].text
      Region = contactaddressregion[0].text
      Country = contactaddresscountry[0].text
      Fax = contactfax[0].text
      Email = contactemail[0].text
      Phone = contactphone[0].text
      URL = contacturl[0].text
      #Here you might want to consider using dictionary or a list
      #For example append Phone to list call phone
      phone.append(Phone)'''
print('done')

#Shortens Code Output
#from google.colab.output import eval_js
#eval_js('google.colab.output.setIframeHeight("500")')
print(type(people.items()))
for p_id, p_info in people.items():
    print("\nPerson ID:", p_id)
    
    for key in p_info:
        print(key + ':', p_info[key])

import pandas as pd
#ok we have some data, now lets make a dataframe
source = [i['region'] for l,i in people.items()]
print(source)
source1 = []
for i in source:
  try:
    #print(i[1])
    source1.append(i[1])
  except:
    source1.append('no region')

relations = ['region' for l,i in people.items()]
print(relations)
target = [i['name'] for l,i in people.items()]
print(target)

kg_df = pd.DataFrame({'source':source1, 'target':target, 'edge':relations})
print(kg_df)
df_mask=kg_df['source']=='Warszawa'
filtered_df = kg_df[df_mask]
print(filtered_df)

import networkx as nx
# create a directed-graph from a dataframe
G=nx.from_pandas_edgelist(filtered_df, "source", "target", 
                          edge_attr=True, create_using=nx.MultiDiGraph())

import matplotlib.pyplot as plt
from tqdm import tqdm
plt.figure(figsize=(12,12))

pos = nx.spring_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
plt.show()

import pandas as pd
#ok we have some data, now lets make a dataframe
source = [i['birthday'] for l,i in people.items()]
print(source)
source1 = []
for i in source:
  try:
    source1.append(i[2])
  except:
    source1.append('no birthday')

relations = ['born' for l,i in people.items()]
print(relations)
target = [i['name'] for l,i in people.items()]
print(target)

kg_df = pd.DataFrame({'source':source1, 'target':target, 'edge':relations})


membersperyear = []
year = []
for i in range(1875,1990):
  df_mask=kg_df['source']== str(i)
  filtered_df = kg_df[df_mask]
#print(filtered_df)
  membersperyear.append(filtered_df.size)
  year.append(i)
#  for i in range(len(membersperyear)):
#    print(membersperyear[i],year[i])
print(membersperyear)
plt.plot(year, membersperyear)
plt.ylabel('Members Per Year')
plt.xlabel('Year')
plt.title('Members in Solidarnsci as Born Year by Year')
plt.show()

# Check if individual went to a polytechnic school


import pandas as pd
#ok we have some data, now lets make a dataframe
source = [i['school'] for l,i in people.items()]
print(source)
source1 = []

for i in source:
  for l in i:
    if l == "Politechniki":
      source1.append(l)
      continue
print(len(source1))
print(source1)
relations = ['region' for l,i in people.items()]
print(relations)
target = [i['name'] for l,i in people.items()]
print(target)

kg_df = pd.DataFrame({'source':source1, 'target':target, 'edge':relations})
print(kg_df)
df_mask=kg_df['source']=='Politechniki'
filtered_df = kg_df[df_mask]
print(filtered_df)

